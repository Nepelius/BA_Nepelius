\chapter{Einleitung}
\label{cha:Einleitung}

\section{Motivation}
Computer Vision ist ein interdisziplinärer technologischer Bereich mit immer zunehmender Relevanz, vor allem in Hinsicht auf Themen wie selbstfahrende Autos \cite{AutonomousDriving}, Überwachungskameras \cite{VideoSurveillance} und Gesichtserkennung \cite{FacialRecognition}. Computer Vision heißt computerbasiertes oder maschinelles Sehen und beschreibt die Analyse von Bilddaten \cite{WikipediaComputerV}. \par

Um Strukturen im Vordergrund von jenen im Hintergrund differenzieren zu können gibt es verschiedenste Verfahren und Methoden \cite{ObjectDetectionIntroductionOnline}. Dabei wird die Struktur anhand ihrer Form, Größe und ihrem Kontrast erkannt und auch klassifiziert. Solche Strukturen nennt man auch Objekte und Verfahren, die sich mit der Erkennung jener beschäftigen, werden unter dem Namen Objekterkennung \cite{ObjectDetectionNeuralNetworks} zusammengefasst. \par
Grundsätzlich bedarf es in verschiedensten Echtwelt-Szenarien der Computer Vision. Es können Autos auf einem Autobahnabschnitt gezählt oder Sicherheitsaspekte durch Gesichtserkennung verbessert werden. In allen praktischen Anwendungsfällen von Computer
Vision wird eine gewisse Arbeit von einem Computer verrichtet, wodurch Prozesse
automatisiert werden.\par
Diese Automatisierung findet auch Verwendung für den Nationalpark Hohe Tauern, da es ein mühsames Verfahren ist, stundenlanges Videomaterial von Wildtierkameras manuell zu analysieren. Ein Algorithmus kann stattdessen diese Analyse der Tierwelt in den österrechischen Hochgebirgsregionen vollziehen.

\section{Problemstellung}
Die Auswertung von Wildtierkameras zur Überwachung der Lebensräume des Nationalpark Hohe Tauern stellt einen immensen Aufwand dar, der mit manueller Sichtung der Tiere verbunden ist. Aus diesem Grund soll die Sichtung computerunterstützt erfolgen, wobei sich der Einsatz von künstlichen neuronalen Netzwerken (KNN) anbietet. Im Zuge dieser Arbeit ist festzustellen, ob Computer Vision das Potential zur genauen und effektiven Erkennung von Tieren unterschiedlicher Größe und unter verschiedensten Wettereinflüssen erfüllen kann, obwohl relevante künstliche Intelligenzmodelle nicht perfekt auf die Tierwelt der österreichischen Alpen abgestimmt sind.\par
Der/Die Benutzer*in soll auf einen Blick sehen können, in welchen Videos sich Tiere befinden und welche sich als "Fehleraufnahmen" herausstellen. Falsche Aufnahmen könnten zum Beispiel solche sein, in denen keine Tiere sondern nur Menschen oder andere sich bewegende Objekte, wie raschelnde Blätter oder Regen/Schnee, zu sehen sind. Somit muss der/die Anwender*in nicht mehr mühsam alle Videos der Wildtierkameras manuell kontrollieren und nach Relevanz aussortieren.

\section{Stand der Technik}

Um Objekte im gegebenen Bild erkennen zu können gibt es viele unterschiedliche Verfahren. Die verschiedenen Ansätze können unterteilt werden in traditionelle Methoden, bei denen mittels lokalem Kontrast und Segmentation vorgegangen wird und den lernbasierten Methoden, die auf KNNs aufbauen \cite{ObjectDetectionReview}. Das Gebiet der generischen Objekterkennung, das via KNN verwirklicht wird, ist wiederum in Gesichtserkennung und Fußgänger-Erkennung differenziert. \par
Die frei verfügbare Bibliothek OpenCV \cite{OpenCV} beinhaltet eine Vielzahl an Klassen und Funktionen für die Bildverarbeitung. Unter Anderem gibt es auch eine Klasse für die sogenannte Hintergrund-Subtraktion. Dabei wird ein aktuelles Bild eines Videos mit einem statischen Hintergrundmodell verglichen, sodass sich bewegende Objekte lokalisiert werden (\cite{ComputerVisionOpenCVBook} S. 191). Obwohl es mit diesem Ansatz gelingt, Bewegung in einem Video festzustellen, gibt es bei dieser Methode einen entscheidenden Nachteil. Wenn die Kamera bewegt wird, dann wird das Ergebnis des Algorithmus verfälscht, weil nun der Hintergrund nicht mehr statisch und das Hintergrundmodell fehlerhaft ist. \par
Optical Flow beschreibt, wie sich Pixel von einem Bild auf ein Anderes bewegen. Diese Bewegung der Pixel wird meist als Pfeil oder "Nadel" visualisiert (\cite{ComputerVisionOpenCVBook} S. 196). Es wurde anfangs der 1980er Jahre entwickelt/erfunden und wird heute noch unter Anderem im Bereich der Bildverarbeitung, Deep Learning und weiteren verwendet \cite{OpticalFlow1980}. Die Voraussetzung für ein gutes Ergebnis sind relativ gleichbleibende Lichtverhältnisse, denn der Algorithmus würde nämlich auch einen Schatten als sich bewegendes Objekt erkennen. \par
Ein Überblick über die Methoden der Bild-Registrierung wird in \cite{FeatureMatchingArticleEfficientAlgorithmsFor} gegeben. Für die Lösung des Problems der Bild-Registrierung gibt es grundsätzlich zwei prominente Ansätze. Ein Ansatz, der sich auf die Korrelation zweier Bilder konzentriert, ist ein für Computer aufwändiger Prozess und bedient sich der originalen Daten des Bildes. Der andere Ansatz beschäftigt sich mit dem Feature Matching. Dieses beschreibt das Finden von Übereinstimmungen zweier Bilder der gleichen Szene/des gleichen Objektes anhand von Features und wurde erstmals um die 2000er Jahre entwickelt. Features sind hierbei markante Stellen im Bild wie Kanten oder Liniensegmente. \par
Dieser Absatz beschreibt die aktuellen Methoden zum Erkennen von Features und zum Verbinden dieser Features, die von folgenden Artikeln zusammengefasst wurden: \cite{FeatureMatchingOnline}, \cite{ObjectDetectionReview}, \cite{FeaturesReview}.
Algorithmen zur Feststellung der Features sind SIFT \cite{FeatureMatchingSIFT} (Scale Invariant Feature Transform), Harris Corner \cite{FeatureMatchingHarrisCorner}, FAST \cite{FeatureMatchingFAST} (Features from Accelerated Segment Test), HOG \cite{FeaturesHOG} (Histograms of oriented gradients), Haar-like \cite{FeaturesHaarLike} und weitere.
Zum Verbinden der Features beider Bilder wird häufig der Brute-Force \cite{FeatureMatchingBruteForce} oder FLANN \cite{FeatureMatchingFLANN} (Fast Library for Approximate Nearest Neighbors) Matcher verwendet. \par
Mit der Entwicklung von Deep-Learning Algorithmen wurde auch der sogenannte YOLO \cite{YOLOOfficialPub} (You Only Look Once) Algorithmus, zum Erkennen und Klassifizieren von Objekten auf Bildern, entwickelt. Ein zentraler Aspekt von Deep-Learning Algorithmen sind neuronale Netzwerke. Es gibt viele verschiedene Formen solcher Netze wie das feedforward- \cite{FeedForwardElsevier}, recurrent- \cite{RecurrentNeuralNetworks} und convolutional \cite{ConvolutionalNeuralNetworks} neural network \cite{NeuralNetwork}. Der YOLO Algorithmus funktioniert nach der feedforward Variante. \par
Bei der Objekterkennung werden Bilddaten manuell mit dem richtigen semantischen Klassenbezeichner markiert, sodass das Netzwerk zum Schluss korrigiert wird wenn es eine falsche Klassifikation getätigt hat. Es handelt sich also um ein überwachtes maschinelles Lernverfahren \cite{SupervisedMachineLearning}. Dieser Vorgang wird oft mit vielen verschiedenen Input-Bildern wiederholt, sodass das Netzwerk anhand von Bilddaten auf das richtige Klassifizieren von Objekten trainiert wird. \par
OpenCV stellt eine Funktion zum Detektieren von Objekten mittels Haar feature-basierend kaskadierenden Klassifizierer zur Verfügung \cite{OpenCVHaarLike}. Keras ist eine frei verfügbare Deep-Learning-Bibliothek, die unter anderem das sogenannte RetinaNet zur Objekterkennung anbietet \cite{KerasRetinaNet}. Verwendet werden hierbei Feature Pyramid Networks, die eine robuste und schnelle Alternative zu gängigen Deep-Learning Verfahren darstellt \cite{KerasPyramidNet}. Das Framework TensorFlow verwirklicht Objekterkennung anhand von zwei Modulen \cite{TensorFlowObj}. Das erste Modul behilft sich der Faster RCNN und der InceptionResNet V2 Methode und besitzt eine hohe Genauigkeit. Das andere Modul ist performanter und kleiner, dafür aber ungenauer und verwendet ssd und MobileNet V2. In ImageJ gibt es eine Methode zum Multi Template Matching \cite{ImageJ}.

\section{Lösungsansatz}
Die automatisierte Erkennung von Wildtieren, wie sie in der Problembeschreibung skizziert wurde, kann durch Anwendung von Verfahren zur Objekterkennung durchgeführt werden. Im Zuge dieser Arbeit wird hierzu ein Verfahren entwickelt, das mittels YOLO Algorithmus arbeitet und relevante Objekte aus Videodaten erkennen und klassifizieren kann. Das Modell des YOLO Algorithmus ist dabei nicht in perfekter Übereinstimmung mit den vom Nationalpark Hohe Tauern bereitgestellten Daten, da das Modell nicht in der Lage ist alle Tierarten zu kategorisieren.